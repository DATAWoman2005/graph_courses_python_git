---
title: "Global Insights Dashboard: Suicide, Happiness, and Internet Use"
author: "my_project"
format: dashboard
theme: sketchy
---

```{python}
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import itables
import numpy as np
import country_converter as cc
from functools import reduce
import dash
```


```{python}
#| output: false
# happiness_score dataset
happiness_data = pd.read_csv("data\hapiscore_whr.csv")

happiness_data
```

```{python}
#| output: false
# changing dataset to a long format
happiness_data_long = happiness_data.melt(id_vars="country")
happiness_data_long
```

```{python}
#| output: false
# changing to representative column names
happiness_data_long = happiness_data.melt(id_vars="country", var_name="year", value_name = "percent_happiness").sort_values(["country", "year"])

happiness_data_long
```

```{python}
#| output: false
# checking datatype
happiness_data_long.dtypes
```

```{python}
#| output: false
# converting the 'year' column to integer type, and coercing errors to NaN
happiness_data_long['year'] = pd.to_numeric(happiness_data_long['year'], errors='coerce')

# Confirm the conversion
print(happiness_data_long['year'].dtype)

```

```{python}
#| output: false
# filtering for year 2017 to 2022
happiness_data_long = happiness_data_long[
    (happiness_data_long['year'] >= 2017) & (happiness_data_long['year'] <= 2022)
]

# Check the result
print(happiness_data_long['year'].unique())
print(happiness_data_long["country"].unique())
print(happiness_data_long.shape)
```

```{python}
#| output: false
# Updating rows where 'country' equals 'UAE'
happiness_data_long.loc[happiness_data_long['country'] == 'UAE', 'country'] = 'United Arab Emirates'

# Verify the change
print(happiness_data_long['country'].unique())
```

```{python}
#| output: false

# converting country names to ISO3 codes
happiness_data_long["country_code"] = cc.convert(happiness_data_long["country"], to="ISO3")

# Verify the result
print(happiness_data_long.head())
print(f"Shape after dropping invalid countries: {happiness_data_long.shape}")
```



```{python}
#| output: false
# suicide_rate dataset
suicide_rate = pd.read_csv("data\suicide_rate_data.csv")

suicide_rate
```

```{python}
#| output: false
# selecting applicable columns
suicide_rate_subset = suicide_rate [["Reference area", "Sex", "TIME_PERIOD", "OBS_VALUE"]]

suicide_rate_subset
```

```{python}
#| output: false
# changing to representative column names
suicide_rate_subset = suicide_rate_subset.rename(columns={"Reference area": "country", "Sex": "sex", "TIME_PERIOD": "year", "OBS_VALUE": "mortality_count"})

suicide_rate_subset = suicide_rate_subset.sort_values(["country", "year"])

suicide_rate_subset
```

```{python}
#| output: false
# dropping rows with 'OECD' or 'European Union' in the 'country' column 
# as only interested in single country names
suicide_rate_subset = suicide_rate_subset[
    ~suicide_rate_subset['country'].str.contains("OECD|European Union", case=False, na=False,regex=True)
]

# Verify the result
print(suicide_rate_subset['country'].unique())
print(f"Shape after dropping OECD and European Union rows: {suicide_rate_subset.shape}")

```

```{python}
#| output: false

# unique number of countries in happiness dataset
suic_country_count = suicide_rate_subset["country"].nunique()

suic_country_count
```

```{python}
#| output: false
# internet_use dataset
internet_use = pd.read_csv ("data\household_internet_use.csv")

internet_use 
```

```{python}
#| output: false
# selecting applicable columns
internet_use_subset = internet_use[["Reference area", "TIME_PERIOD", "OBS_VALUE"]]

internet_use_subset
```

```{python}
#| output: false
# changing to representative column names
internet_use_subset = internet_use_subset.rename(columns={"Reference area": "country", "TIME_PERIOD": "year", "OBS_VALUE": "percent_internet_household"})

internet_use_subset
```

```{python}
#| output: false
# dropping rows with 'OECD' or 'European Union' in the 'country' column
internet_use_subset = internet_use_subset[
    ~internet_use_subset['country'].str.contains("OECD|European Union", case=False, na=False,regex=True)
]

# Verify the result
print(internet_use_subset['country'].unique())
print(f"Shape after dropping OECD and European Union rows: {internet_use_subset.shape}")

```

```{python}
#| output: false
# rounding to 1 decimal for consistency with other datasets
internet_use_subset["percent_internet_household"] = internet_use_subset["percent_internet_household"].round(1)

internet_use_subset
```

```{python}
#| output: false
internet_use_subset["country_code"]  = cc.convert(internet_use_subset["country"], to="ISO3")


# Verify the result
print(internet_use_subset.head())
print(f"New shape of the DataFrame: {internet_use_subset.shape}")
```

```{python}
#| output: false
internet_use_subset = internet_use_subset.sort_values(["country","year"])
```


```{python}
#| output: false
#calculating missing values for each dataset
happiness_missing = happiness_data_long.isna().sum()
internet_missing = internet_use_subset.isna().sum()
suicide_missing = suicide_rate_subset.isna().sum()


# combining the results into a single DataFrame
missing_summary = pd.DataFrame({
   'dataset': ['percent_happiness', 'internet_use', 'suicide_rate'],
   'country': [happiness_missing['country'], internet_missing['country'], suicide_missing['country']],
   'year': [happiness_missing['year'], internet_missing['year'], suicide_missing['year']],
   'value_column': [happiness_missing['percent_happiness'], internet_missing['percent_internet_household'], suicide_missing['mortality_count']]
})

missing_summary                      
```

```{python}
#| output: false
# reshaping with melt and naming columns for clarity
missing_summary = missing_summary.melt(
    id_vars='dataset', var_name='dataset_columns', value_name='missing_count'
).sort_values('dataset')
missing_summary
```

```{python}
#| output: false
# bar chart for missing values
fig = px.bar(
    missing_summary,
    x='dataset_columns',
    y='missing_count',
    color='dataset',
    title='Missing Values per Column Across Datasets',
    labels={'missing_count': 'Count of Missing Values', 'dataset_columns': 'Columns'},
    barmode='group'
)

fig.show()
```

```{python}
#| output: false
# dropping missing value from dataset
happiness_data_long.dropna(inplace=True)

```

```{python}
#| output: false
# function to check any persistent missing values
def check_missing_data(df, name):
    print(f"Missing Data Summary for {name}:")
    print(df.isna().sum())
    print("-" * 40)

# Check for missing values in each dataset
check_missing_data(happiness_data_long, "Happiness Data")
check_missing_data(internet_use_subset, "Internet Use Data")
check_missing_data(suicide_rate_subset, "Suicide Rate Data")

```

```{python}
#| output: false

# unique number of countries in happiness dataset
happy_countries = happiness_data_long["country"].nunique()

happy_countries
```

```{python}
#| output: false
# creating a pivoted version of the 'suicide_rate_subset' dataFrame 
# to analyze mortality rates by sex (Male, Female, Total)
# without modifying the original 'suicide_rate_subset
# pivoting the data so each sex becomes its own column
suicide_rate_pivot = suicide_rate_subset.pivot_table(
    index=['country', 'year'],
    columns='sex',
    values='mortality_count',
    aggfunc='sum'  # Aggregate if duplicates exist
).reset_index()

# renaming the columns for clarity
suicide_rate_pivot.columns.name = None  # removing column index name
suicide_rate_pivot = suicide_rate_pivot.rename(columns={
    'Male': 'mortality_male',
    'Female': 'mortality_female',
    'Total': 'mortality_total'
})

suicide_rate_pivot["country_code"]  = cc.convert(suicide_rate_pivot["country"], to="ISO3")

# cleaned dataset
suicide_rate_pivot.head()
```

```{python}
#| output: false
# filtering to keep only the  rows with 'Total' values
suicide_rate_filtered = suicide_rate_subset[suicide_rate_subset["sex"] == "Total"]

suicide_rate_filtered
```

```{python}
#| output: false
# dropping the 'sex' column as it's no longer needed
suicide_rate_filtered = suicide_rate_filtered.drop(columns=["sex"]).sort_values(["country", "year"])

suicide_rate_filtered.head()
```

```{python}
#| output: false
suicide_rate_filtered ["country_code"] = cc.convert(suicide_rate_filtered ["country"], to="ISO3")

# Verify the result
print(suicide_rate_filtered .head())
print(f"New shape of the DataFrame: {suicide_rate_filtered.shape}")
```

```{python}
#| output: false
print(happiness_data_long.shape)
print(internet_use_subset.shape)
print(suicide_rate_filtered.shape)
print(suicide_rate_pivot.shape)

```


```{python}
#| output: false
# joining suicide_rate with happiness on 'country_code' and 'year'
data_frames = [suicide_rate_filtered, 
    happiness_data_long, internet_use_subset]
df_merged = reduce(lambda left, right: pd.merge(left, right,  on=['country_code','year'],
    how='outer'), data_frames)

# replacing missing values
# replacing NaN with 'Unknown' for object (string) columns
for col in df_merged.select_dtypes(include='object').columns:
    df_merged[col].fillna('Unknown', inplace=True)

# replacing NaN with -1 for numeric columns
for col in df_merged.select_dtypes(include='number').columns:
    df_merged[col].fillna(-1, inplace=True)

df_merged.head(20)
```

```{python}
#| output: false
df_merged = df_merged.drop(columns=["country_x", "country"])
df_merged.rename(columns={"country_y": "country"}, inplace=True)
df_merged.head(20)
```

```{python}
#| output: false
# rearranging columns in a more intuitive order
column_order = ['country_code', 'country', 'year', 'percent_happiness', 'mortality_count', 'percent_internet_household']
if set(column_order).issubset(df_merged.columns):
    df_merged = df_merged[column_order]

# Check the data types
df_merged
```

```{python}
#| output: false
df_merged.to_csv('final_merged.csv', index=False)
```

```{python}

#| output: false
# 1. Global Average Happiness
global_avg_happiness = happiness_data_long["percent_happiness"].mean()
print(f"{global_avg_happiness:.1f}%.")

# 2. Happiest Year Globally
happiest_year = (
    happiness_data_long.groupby("year")["percent_happiness"].mean()
    .idxmax()
)
happiest_year_avg = (
    happiness_data_long.groupby("year")["percent_happiness"].mean()
    .max()
)
print(f"The happiest year globally was {happiest_year}, with an average happiness of {happiest_year_avg:.1f}%.")

# 3. Most Stable Performer
country_variability = (
    happiness_data_long.groupby("country")["percent_happiness"].std()
)
most_stable_country = country_variability.idxmin()
least_variability = country_variability.min()
print(f"The most stable performer was {most_stable_country}, with a variability of ±{least_variability:.1f}%.")

# 4. Global Happiness Gap
happiest_country_avg = (
    happiness_data_long.groupby("country")["percent_happiness"].mean()
    .max()
)
least_happy_country_avg = (
    happiness_data_long.groupby("country")["percent_happiness"].mean()
    .min()
)
happiness_gap = happiest_country_avg - least_happy_country_avg
print(f"The global happiness gap is {happiness_gap:.1f} percentage points.")

```


```{python}
#| output: false
# Find the top 10 countries overall based on maximum percent_happiness
top_countries_overall = df_merged.groupby("country")["percent_happiness"].max().nlargest(10).index

# Filter the data to include only these countries across all years
consistent_top_countries = df_merged[df_merged["country"].isin(top_countries_overall)]

# Create a bar chart
fig = px.bar(
    consistent_top_countries,
    x="country_code",
    y="percent_happiness",
    color="year",
    labels={"percent_happiness": "Happiness Score (%)", "country_code": "ISO3"},
    text="percent_happiness"
)

fig.update_traces(texttemplate='%{text}', textposition='inside')
fig.update_layout(
    xaxis_title="Finland Dominates Happiness Rankings; Canada Shines in 9th place at 74.2%!",
    yaxis_title="Percent Happiness",
    showlegend=True
)

fig.show()


# Calculate the highest scoring country and its score
highest_country = consistent_top_countries.groupby("country")["percent_happiness"].max().idxmax()
highest_score = consistent_top_countries.groupby("country")["percent_happiness"].max().max()

# Calculate Canada's ranking
country_scores = consistent_top_countries.groupby("country")["percent_happiness"].max()
ranked_countries = country_scores.sort_values(ascending=False).reset_index()
canada_rank = ranked_countries[ranked_countries["country"] == "Canada"].index[0] + 1
canada_score = country_scores["Canada"]

# Output in two sentences
output = (
    f"For 5 Years Straight, {highest_country} Tops the Global Happiness Chart at {highest_score:.1f}% while Canada Proudly Ranks {canada_rank}th at {canada_score:.1f}%"
)
print(output)

```


```{python}
#| output: false

# Calculate global average happiness per year
global_trends = happiness_data_long.groupby("year")["percent_happiness"].mean().reset_index()

# Create a line chart
line_fig = px.line(
    global_trends,
    x="year",
    y="percent_happiness",
    labels={"percent_happiness": "Avg Happiness Score (%)", "year": "Year"},
    markers=True
)

# Annotate key events (e.g., pandemic in 2020)
line_fig.add_annotation(
    x=2020,
    y=global_trends.loc[global_trends["year"] == 2020, "percent_happiness"].values[0],
    text="Pandemic Impact",
    showarrow=True,
    arrowhead=2,
    ax=-40,
    ay=-40
)

# Show the chart
line_fig.show()

```

```{python}
#| output: false

# Calculate variability for each country
country_variability = happiness_data_long.groupby("country")["percent_happiness"].std()

# Identify the most stable performer
most_stable_country = country_variability.idxmin()
least_variability = country_variability.min()

# Print the result
print(f"The most stable performer was {most_stable_country}, with a variability of ±{least_variability:.1f}%.")

# Create a DataFrame for visualization
variability_df = country_variability.reset_index().rename(columns={"percent_happiness": "variability"})

# Sort the data by variability
variability_df = variability_df.sort_values(by="variability")

# Plot a line chart
scatter_fig = px.line(
    variability_df,
    x="variability",
    y="country",
    title="Happiness Variability by Country",
    labels={"variability": "Variability (Standard Deviation)", "country": "Country"},
    markers=True,
    color_discrete_sequence=["blue"],
)

# Highlight the most stable performer
scatter_fig.add_scatter(
    x=[least_variability],
    y=[most_stable_country],
    mode="markers+text",
    text=[f"Most Stable Country: {most_stable_country} with a variability of ±{least_variability:.1f}%"],
    marker=dict(size=10, color="red"),
    textposition="bottom right"
)

# Show the chart
scatter_fig.show()

```

```{python}
#| output: false

# Create a DataFrame for variability
variability_df = country_variability.reset_index().rename(columns={"percent_happiness": "variability"})

# Sort the data by variability
variability_df = variability_df.sort_values(by="variability").reset_index(drop=True)

# Add a ranking column for variability
variability_df["Variability Rank"] = variability_df.index + 1

# Calculate mean happiness score for each country
average_happiness = happiness_data_long.groupby("country")["percent_happiness"].mean()

# Merge average happiness scores with variability DataFrame
variability_df = variability_df.merge(average_happiness.reset_index(), on="country")
variability_df = variability_df.rename(columns={"percent_happiness": "average_happiness"})

# Add a ranking column for happiness score
variability_df = variability_df.sort_values(by="average_happiness", ascending=False).reset_index(drop=True)
variability_df["Happiness Rank"] = variability_df.index + 1

# Extract the top 10 most consistent countries by variability
top_10_consistent = variability_df.nsmallest(10, "variability")

# Print the top 10 table for reference
print("\nTop 10 Most Consistent Countries:")
print(top_10_consistent[["country", "variability", "average_happiness", "Variability Rank", "Happiness Rank"]])

#| output: false
# Extract the top 10 most consistent countries by variability
top_10_consistent = variability_df.nsmallest(10, "variability")

# Define cell colors for gradient effect
variability_colors = [
    f"rgba({255-int(value*45)}, {255-int(value*15)}, 255, 0.8)"
    for value in top_10_consistent["variability"]
]
happiness_colors = [
    f"rgba(255, {255-int(value)}, 150, 0.8)"
    for value in top_10_consistent["average_happiness"]
]
rank_colors = [
    f"rgba({255-int(value*25)}, {255-int(value*15)}, 255, 0.8)"
    for value in top_10_consistent["Variability Rank"]
]

# Create a styled table with colors
fig_top_10_table = go.Figure(
    data=[
        go.Table(
            header=dict(
                values=[
                    "Country",
                    "Variability (Standard Deviation)",
                    "Average Happiness Score",
                    "Variability Rank",
                    "Happiness Rank",
                ],
                fill_color="lightblue",
                align="left",
                font=dict(size=12, color="black"),
            ),
            cells=dict(
                values=[
                    top_10_consistent["country"],
                    top_10_consistent["variability"].round(1),
                    top_10_consistent["average_happiness"].round(1),
                    top_10_consistent["Variability Rank"],
                    top_10_consistent["Happiness Rank"],
                ],
                fill_color=[
                    ["white"] * len(top_10_consistent),  # No color for 'Country'
                    variability_colors,  # Gradient for 'Variability'
                    happiness_colors,  # Gradient for 'Average Happiness'
                    rank_colors,  # No color for 'Variability Rank'
                    ["white"] * len(top_10_consistent),  # No color for 'Happiness Rank'
                ],
                align="left",
                font=dict(size=11, color="black"),
            ),
        )
    ]
)

# Update layout for better visualization

# Show the table
fig_top_10_table.show()
```

# Rising and Falling Joy: A 5-Year Snapshot of Global Happiness

## {height = "10%"}
::: {.valuebox title="Countries Represented in Analysis" color="primary"}
`{python} happy_countries`
:::

::: {.valuebox title="Global Avg Happiness" color="primary"}
`{python} str(global_avg_happiness.round(1))`%
:::

::: {.valuebox title="Happiest Country Avg" color="primary"}
`{python} str(happiest_country_avg.round(1))`%
:::

::: {.valuebox title="Happiest Year" color="primary"}
`{python} str(happiest_year)`
:::


::: {.valuebox title="Happiness Gap" color="primary"}
`{python} str(happiness_gap.round(1))`%
:::


## Row{45% width="70%"}

::: {.card title="From Blue to Gold: Track of Global Happiness Among the Top 10 Countries"}
```{python}
fig.show()
```
:::

### {.tabset height="45%" width="30%"}

::: {.card title="Happiness Peaked: A Pandemic Story of Hope and Decline"}
```{python}
line_fig.show()
```
:::

::: {.card title="Insight"}
The line chart visualizes the global average happiness trend from 2017 to 2022. It shows a steady rise in happiness from 2017 to 2020, peaking during the pandemic year at 57.5%. While this might seem counterintuitive, it reflects resilience in high-ranking nations like Finland and Denmark, which helped maintain high global averages. After 2020, a noticeable decline highlights the longer-term impacts of the pandemic, economic challenges, and global uncertainty. This visual emphasizes how global averages can mask country-specific variations, making it essential to analyze individual trends for a deeper understanding.
:::


## {height="45%" width="70%"}
::: {.card title="Stability at a Cost: Happiness at Rock Bottom"}
```{python}
scatter_fig.show()
```
:::


::: {.card title="Global Happiness Stability: When Consistency Masks Contrasting Realities"}
```{python}
fig_top_10_table.show()
```
:::


```{python}
#| output: false
global_avg_suicide_mortality = suicide_rate_pivot["mortality_total"].mean()
global_avg_suicide_mortality

average_by_year = suicide_rate_pivot.groupby('year')['mortality_total'].mean()

# Highest Suicide Mortality Year Globally
year_with_highest_rate =  suicide_rate_pivot.groupby('year')['mortality_total'].mean().idxmax()

highest_avg_rate = average_by_year.max()
year_with_lowest_rate = average_by_year.idxmin()
lowest_avg_rate = average_by_year.min()

print(f"Year with Highest Average Suicide Mortality Rate: {year_with_highest_rate}")
print(f"Average Mortality Rate for that Year: {highest_avg_rate:.2f} per 100,000 people")
print(f"Year with Lowest Average Suicide Mortality Rate: {year_with_lowest_rate}")
print(f"Average Mortality Rate for that Year: {lowest_avg_rate:.2f} per 100,000 people")
```

```{python}
#| output: False
# global average mortality rates for males and females
global_avg_male = suicide_rate_pivot['mortality_male'].mean()
global_avg_female = suicide_rate_pivot['mortality_female'].mean()

# male-to-female ratio
male_to_female_ratio = global_avg_male / global_avg_female

# formating the ratio as X:1
formatted_ratio = f"{male_to_female_ratio:.1f}:1"


print(f"Global Male-to-Female Suicide Mortality Ratio: {formatted_ratio}")

```


```{python}
#| output: False
fig_map = px.choropleth(
    suicide_rate_pivot,
    locations="country_code",            # Column with ISO-3 country codes
    color="mortality_total",            # Column for coloring (suicide rate)
    hover_name="country", 
    hover_data={"mortality_male": True,"mortality_female": True},
    animation_frame="year",  # Add animation by year 
    color_continuous_scale="Viridis",     # Color scale for the map
    labels={"mortality_total": "Suicide Rate (per 100k)"},  # Label for color bar
)

# Update layout for better visualization
fig.update_layout(
    geo=dict(
        showframe=True,
        showcoastlines=True,
        projection_type="natural earth"  # Choose a suitable projection type
    ),
)

# Show the plot
fig_map.show()
```

# Whats going on

## {height = "10%"}
::: {.valuebox title="Countries Represented in Analysis" color="primary"}
`{python} suic_country_count`  
:::

::: {.valuebox title="Global Avg Suicide Rate" color="primary"}
`{python} str(global_avg_suicide_mortality.round(1))`% 
:::


::: {.valuebox title="Year with Highest Rate" color="primary"}
`{python} str(year_with_highest_rate)`
:::

::: {.valuebox title="Year with Lowest Rate" color="primary"}
`{python} str(year_with_lowest_rate)`
:::

::: {.valuebox title= "Staggering Male Suicide Disparity" color="primary"}
`{python} formatted_ratio`
:::

##
::: {.callout-note}
### Key Insights
- **Countries Analyzed**: Data covers 46 countries.
- **Global Average Suicide Rate**: Calculated as 10.8 per 100k (2017–2022).
- **Year with Highest Rate**: 2022.
- **Year with Lowest Rate**: 2018.
- **Male-to-Female Suicide Ratio**: 3.7:1 - Men are 3.7 times more likely to die by suicide than women globally.
  - Global suicide rates are presented per 100,000 population for standardized comparison.
:::

## Row{45% width="70%"}

::: {.card title="Global Suicide Rate Distribution"}
```{python}
fig_map.show()
```
:::